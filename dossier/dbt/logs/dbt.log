[0m14:32:54.709397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a08a6cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a0892de9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a088c6d940>]}


============================== 14:32:54.719095 | 96f6794e-ceb7-4c09-a0a6-d8b7a4206fc4 ==============================
[0m14:32:54.719095 [info ] [MainThread]: Running with dbt=1.8.3
[0m14:32:54.719766 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dossier/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dossier/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:32:54.845703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96f6794e-ceb7-4c09-a0a6-d8b7a4206fc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a088b26580>]}
[0m14:32:54.860180 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-_0wcu5fz'
[0m14:32:54.860928 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:32:55.363664 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:32:55.364570 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:32:55.645148 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:32:55.688235 [info ] [MainThread]: Updating lock file in file path: /opt/airflow/dossier/dbt/package-lock.yml
[0m14:32:55.692242 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-f7r0um8i'
[0m14:32:55.700890 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:32:57.081051 [info ] [MainThread]: Installed from version 1.1.1
[0m14:32:57.081691 [info ] [MainThread]: Updated version available: 1.2.0
[0m14:32:57.082254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '96f6794e-ceb7-4c09-a0a6-d8b7a4206fc4', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a088a1edf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a088a1edc0>]}
[0m14:32:57.082802 [info ] [MainThread]: 
[0m14:32:57.083292 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m14:32:57.084505 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.4274883, "process_user_time": 1.533128, "process_kernel_time": 0.142332, "process_mem_max_rss": "89936", "process_in_blocks": "27432", "process_out_blocks": "2240"}
[0m14:32:57.085167 [debug] [MainThread]: Command `dbt deps` succeeded at 14:32:57.085043 after 2.43 seconds
[0m14:32:57.085632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a08a6cc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a08a50e940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74a088a70370>]}
[0m14:32:57.086124 [debug] [MainThread]: Flushing usage events
[0m14:39:27.378126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7dc109a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7da6df670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7da6dfca0>]}


============================== 14:39:27.384032 | 1f75539e-afe8-45d1-8e84-4ec3eb416a01 ==============================
[0m14:39:27.384032 [info ] [MainThread]: Running with dbt=1.8.3
[0m14:39:27.384765 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dossier/dbt/logs', 'profiles_dir': '.', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir .', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:39:27.554291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7da6de4f0>]}
[0m14:39:27.610132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d9d694c0>]}
[0m14:39:27.614204 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m14:39:27.649004 [debug] [MainThread]: checksum: 30bd4080c2bc8dee5936f8f60083ffbe1c906859d0fd965607c2144031479456, vars: {}, profile: , target: , version: 1.8.3
[0m14:39:27.650480 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:39:27.651285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d99da520>]}
[0m14:39:29.297547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d9141a60>]}
[0m14:39:29.414305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d9127dc0>]}
[0m14:39:29.414975 [info ] [MainThread]: Found 4 models, 2 sources, 529 macros
[0m14:39:29.415479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d9175e50>]}
[0m14:39:29.417205 [info ] [MainThread]: 
[0m14:39:29.417950 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:39:29.423363 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m14:39:29.473551 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m14:39:29.474066 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m14:39:29.474473 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:39:29.481423 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m14:39:29.483167 [debug] [ThreadPool]: On list_airflow: Close
[0m14:39:29.484873 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public)
[0m14:39:29.493141 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m14:39:29.493649 [debug] [ThreadPool]: On list_airflow_public: BEGIN
[0m14:39:29.494045 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:39:29.497563 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.498083 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m14:39:29.498510 [debug] [ThreadPool]: On list_airflow_public: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "list_airflow_public"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m14:39:29.501326 [debug] [ThreadPool]: SQL status: SELECT 44 in 0.0 seconds
[0m14:39:29.503700 [debug] [ThreadPool]: On list_airflow_public: ROLLBACK
[0m14:39:29.504184 [debug] [ThreadPool]: On list_airflow_public: Close
[0m14:39:29.516836 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.517286 [debug] [MainThread]: On master: BEGIN
[0m14:39:29.517664 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:39:29.521269 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.521728 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.522195 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:39:29.525134 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:39:29.526471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d9127f10>]}
[0m14:39:29.527004 [debug] [MainThread]: On master: ROLLBACK
[0m14:39:29.527565 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.527964 [debug] [MainThread]: On master: BEGIN
[0m14:39:29.528685 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.529095 [debug] [MainThread]: On master: COMMIT
[0m14:39:29.529476 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.529853 [debug] [MainThread]: On master: COMMIT
[0m14:39:29.530334 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:39:29.530724 [debug] [MainThread]: On master: Close
[0m14:39:29.531308 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:39:29.531749 [info ] [MainThread]: 
[0m14:39:29.538626 [debug] [Thread-1  ]: Began running node model.airflow.dim_customer
[0m14:39:29.539378 [info ] [Thread-1  ]: 1 of 4 START sql table model public.dim_customer ............................... [RUN]
[0m14:39:29.540055 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_airflow_public, now model.airflow.dim_customer)
[0m14:39:29.540574 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_customer
[0m14:39:29.553697 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_customer"
[0m14:39:29.554561 [debug] [Thread-1  ]: Began executing node model.airflow.dim_customer
[0m14:39:29.607971 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_customer"
[0m14:39:29.608930 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:39:29.609433 [debug] [Thread-1  ]: On model.airflow.dim_customer: BEGIN
[0m14:39:29.609898 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:39:29.613469 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.614086 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:39:29.614613 [debug] [Thread-1  ]: On model.airflow.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_customer"} */

  
    

  create  table "airflow"."public"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- dim_customer.sql

-- Create the dimension table
WITH customer_cte AS (
	SELECT DISTINCT
	    md5(cast(coalesce(cast(customerid as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(Country as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as customer_id,
	    Country AS country
	FROM products
	WHERE CustomerID IS NOT NULL
)
SELECT
    t.*,
	cm.iso
FROM customer_cte t
LEFT JOIN country cm ON t.country = cm.nicename
  );
  
[0m14:39:29.615445 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "products" does not exist
LINE 19:  FROM products
               ^

[0m14:39:29.615970 [debug] [Thread-1  ]: On model.airflow.dim_customer: ROLLBACK
[0m14:39:29.618317 [debug] [Thread-1  ]: On model.airflow.dim_customer: Close
[0m14:39:29.623742 [debug] [Thread-1  ]: Database Error in model dim_customer (models/transform/dim_customer.sql)
  relation "products" does not exist
  LINE 19:  FROM products
                 ^
  compiled Code at target/run/airflow/models/transform/dim_customer.sql
[0m14:39:29.625738 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7db3eb640>]}
[0m14:39:29.626568 [error] [Thread-1  ]: 1 of 4 ERROR creating sql table model public.dim_customer ...................... [[31mERROR[0m in 0.08s]
[0m14:39:29.627358 [debug] [Thread-1  ]: Finished running node model.airflow.dim_customer
[0m14:39:29.627900 [debug] [Thread-1  ]: Began running node model.airflow.dim_datetime
[0m14:39:29.628501 [info ] [Thread-1  ]: 2 of 4 START sql table model public.dim_datetime ............................... [RUN]
[0m14:39:29.629252 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.airflow.dim_customer, now model.airflow.dim_datetime)
[0m14:39:29.629736 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_datetime
[0m14:39:29.632743 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_datetime"
[0m14:39:29.633435 [debug] [Thread-1  ]: Began executing node model.airflow.dim_datetime
[0m14:39:29.640598 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_datetime"
[0m14:39:29.641416 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:39:29.642059 [debug] [Thread-1  ]: On model.airflow.dim_datetime: BEGIN
[0m14:39:29.642802 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:39:29.646503 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.647380 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:39:29.647933 [debug] [Thread-1  ]: On model.airflow.dim_datetime: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_datetime"} */

  
    

  create  table "airflow"."public"."dim_datetime__dbt_tmp"
  
  
    as
  
  (
    -- dim_datetime.sql

-- Create a CTE to extract date and time components
WITH datetime_cte AS (  
  SELECT DISTINCT
    invoicedate AS datetime_id,
    CASE
      WHEN LENGTH(CAST(invoicedate AS VARCHAR)) = 16 THEN
        -- Date format: "DD/MM/YYYY HH:MI"
        TO_TIMESTAMP(CAST(invoicedate as TEXT ), 'DD/MM/YYYY HH24:MI')
      WHEN LENGTH(CAST(invoicedate AS VARCHAR)) <= 14 THEN
        -- Date format: "MM/DD/YY HH:MI"

        TO_TIMESTAMP(CAST(invoicedate as TEXT ), 'MM/DD/YY HH24:MI')
      ELSE
        NULL
    END AS date_part
  FROM products
  WHERE invoicedate IS NOT NULL
)
SELECT
  datetime_id,
  date_part AS datetime,
  EXTRACT(YEAR FROM date_part) AS year,
  EXTRACT(MONTH FROM date_part) AS month,
  EXTRACT(DAY FROM date_part) AS day,
  EXTRACT(HOUR FROM date_part) AS hour,
  EXTRACT(MINUTE FROM date_part) AS minute,
  EXTRACT(ISODOW FROM date_part) AS weekday
FROM datetime_cte
  );
  
[0m14:39:29.648942 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "products" does not exist
LINE 29:   FROM products
                ^

[0m14:39:29.649446 [debug] [Thread-1  ]: On model.airflow.dim_datetime: ROLLBACK
[0m14:39:29.650316 [debug] [Thread-1  ]: On model.airflow.dim_datetime: Close
[0m14:39:29.651540 [debug] [Thread-1  ]: Database Error in model dim_datetime (models/transform/dim_datetime.sql)
  relation "products" does not exist
  LINE 29:   FROM products
                  ^
  compiled Code at target/run/airflow/models/transform/dim_datetime.sql
[0m14:39:29.652152 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d84897c0>]}
[0m14:39:29.653036 [error] [Thread-1  ]: 2 of 4 ERROR creating sql table model public.dim_datetime ...................... [[31mERROR[0m in 0.02s]
[0m14:39:29.653820 [debug] [Thread-1  ]: Finished running node model.airflow.dim_datetime
[0m14:39:29.654398 [debug] [Thread-1  ]: Began running node model.airflow.dim_product
[0m14:39:29.655025 [info ] [Thread-1  ]: 3 of 4 START sql table model public.dim_product ................................ [RUN]
[0m14:39:29.655768 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.airflow.dim_datetime, now model.airflow.dim_product)
[0m14:39:29.656295 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_product
[0m14:39:29.662415 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_product"
[0m14:39:29.663162 [debug] [Thread-1  ]: Began executing node model.airflow.dim_product
[0m14:39:29.669552 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_product"
[0m14:39:29.670262 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:39:29.670720 [debug] [Thread-1  ]: On model.airflow.dim_product: BEGIN
[0m14:39:29.671205 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:39:29.674620 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.675171 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:39:29.675648 [debug] [Thread-1  ]: On model.airflow.dim_product: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_product"} */

  
    

  create  table "airflow"."public"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- dim_product.sql
-- StockCode isn't unique, a product with the same id can have different and prices
-- Create the dimension table
SELECT DISTINCT
    md5(cast(coalesce(cast(stockcode as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(description as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(unitprice as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as product_id,
		stockcode AS stock_code,
    description AS description,
    unitprice AS price
FROM products
WHERE stockcode IS NOT NULL
AND unitprice > 0
  );
  
[0m14:39:29.676497 [debug] [Thread-1  ]: Postgres adapter: Postgres error: relation "products" does not exist
LINE 20: FROM products
              ^

[0m14:39:29.676989 [debug] [Thread-1  ]: On model.airflow.dim_product: ROLLBACK
[0m14:39:29.677765 [debug] [Thread-1  ]: On model.airflow.dim_product: Close
[0m14:39:29.678885 [debug] [Thread-1  ]: Database Error in model dim_product (models/transform/dim_product.sql)
  relation "products" does not exist
  LINE 20: FROM products
                ^
  compiled Code at target/run/airflow/models/transform/dim_product.sql
[0m14:39:29.679514 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1f75539e-afe8-45d1-8e84-4ec3eb416a01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7d85cf2e0>]}
[0m14:39:29.680499 [error] [Thread-1  ]: 3 of 4 ERROR creating sql table model public.dim_product ....................... [[31mERROR[0m in 0.02s]
[0m14:39:29.681487 [debug] [Thread-1  ]: Finished running node model.airflow.dim_product
[0m14:39:29.682594 [debug] [Thread-1  ]: Began running node model.airflow.fct_invoices
[0m14:39:29.683207 [info ] [Thread-1  ]: 4 of 4 SKIP relation public.fct_invoices ....................................... [[33mSKIP[0m]
[0m14:39:29.683845 [debug] [Thread-1  ]: Finished running node model.airflow.fct_invoices
[0m14:39:29.685122 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.685586 [debug] [MainThread]: On master: BEGIN
[0m14:39:29.685987 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:39:29.689439 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:39:29.689979 [debug] [MainThread]: On master: COMMIT
[0m14:39:29.690512 [debug] [MainThread]: Using postgres connection "master"
[0m14:39:29.691164 [debug] [MainThread]: On master: COMMIT
[0m14:39:29.691962 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:39:29.692713 [debug] [MainThread]: On master: Close
[0m14:39:29.693650 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:39:29.694332 [debug] [MainThread]: Connection 'model.airflow.dim_product' was properly closed.
[0m14:39:29.695182 [info ] [MainThread]: 
[0m14:39:29.695944 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 0.28 seconds (0.28s).
[0m14:39:29.698053 [debug] [MainThread]: Command end result
[0m14:39:29.749941 [info ] [MainThread]: 
[0m14:39:29.750590 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m14:39:29.751078 [info ] [MainThread]: 
[0m14:39:29.751738 [error] [MainThread]:   Database Error in model dim_customer (models/transform/dim_customer.sql)
  relation "products" does not exist
  LINE 19:  FROM products
                 ^
  compiled Code at target/run/airflow/models/transform/dim_customer.sql
[0m14:39:29.752271 [info ] [MainThread]: 
[0m14:39:29.752857 [error] [MainThread]:   Database Error in model dim_datetime (models/transform/dim_datetime.sql)
  relation "products" does not exist
  LINE 29:   FROM products
                  ^
  compiled Code at target/run/airflow/models/transform/dim_datetime.sql
[0m14:39:29.753346 [info ] [MainThread]: 
[0m14:39:29.753906 [error] [MainThread]:   Database Error in model dim_product (models/transform/dim_product.sql)
  relation "products" does not exist
  LINE 20: FROM products
                ^
  compiled Code at target/run/airflow/models/transform/dim_product.sql
[0m14:39:29.754383 [info ] [MainThread]: 
[0m14:39:29.754944 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=1 TOTAL=4
[0m14:39:29.756207 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.4284768, "process_user_time": 3.560263, "process_kernel_time": 0.140642, "process_mem_max_rss": "112312", "process_in_blocks": "14192", "process_out_blocks": "3264", "command_success": false}
[0m14:39:29.757084 [debug] [MainThread]: Command `dbt run` failed at 14:39:29.756946 after 2.43 seconds
[0m14:39:29.757604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7dc109a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7db3b0100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77c7dbdf9ac0>]}
[0m14:39:29.758103 [debug] [MainThread]: Flushing usage events
[0m14:41:42.594157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023ff822940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fdd05880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fddffd00>]}


============================== 14:41:42.600539 | 7cc640fe-bd5e-44d6-a19f-9013e4784d54 ==============================
[0m14:41:42.600539 [info ] [MainThread]: Running with dbt=1.8.3
[0m14:41:42.601193 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dossier/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:41:42.767712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fddf1940>]}
[0m14:41:42.830012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fddf1ac0>]}
[0m14:41:42.830926 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m14:41:42.860905 [debug] [MainThread]: checksum: 30bd4080c2bc8dee5936f8f60083ffbe1c906859d0fd965607c2144031479456, vars: {}, profile: , target: , version: 1.8.3
[0m14:41:43.024462 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:41:43.025028 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:41:43.076892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fcc648e0>]}
[0m14:41:43.207019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc96b3a0>]}
[0m14:41:43.207733 [info ] [MainThread]: Found 4 models, 2 sources, 529 macros
[0m14:41:43.208251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fcdffee0>]}
[0m14:41:43.210015 [info ] [MainThread]: 
[0m14:41:43.210790 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:41:43.216551 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m14:41:43.268592 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m14:41:43.269208 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m14:41:43.269676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:41:43.275163 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m14:41:43.276940 [debug] [ThreadPool]: On list_airflow: Close
[0m14:41:43.279111 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public)
[0m14:41:43.287825 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m14:41:43.288419 [debug] [ThreadPool]: On list_airflow_public: BEGIN
[0m14:41:43.288879 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:41:43.292640 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:41:43.293228 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m14:41:43.293777 [debug] [ThreadPool]: On list_airflow_public: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "list_airflow_public"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m14:41:43.296779 [debug] [ThreadPool]: SQL status: SELECT 46 in 0.0 seconds
[0m14:41:43.299594 [debug] [ThreadPool]: On list_airflow_public: ROLLBACK
[0m14:41:43.300263 [debug] [ThreadPool]: On list_airflow_public: Close
[0m14:41:43.317048 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:43.317691 [debug] [MainThread]: On master: BEGIN
[0m14:41:43.318235 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:41:43.322152 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:41:43.322876 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:43.323650 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:41:43.327659 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:41:43.329329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc9b7f40>]}
[0m14:41:43.329986 [debug] [MainThread]: On master: ROLLBACK
[0m14:41:43.330674 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:43.331168 [debug] [MainThread]: On master: BEGIN
[0m14:41:43.331908 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:41:43.332437 [debug] [MainThread]: On master: COMMIT
[0m14:41:43.332921 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:43.333396 [debug] [MainThread]: On master: COMMIT
[0m14:41:43.333969 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:41:43.334455 [debug] [MainThread]: On master: Close
[0m14:41:43.335165 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:41:43.335749 [info ] [MainThread]: 
[0m14:41:43.343955 [debug] [Thread-1  ]: Began running node model.airflow.dim_customer
[0m14:41:43.344841 [info ] [Thread-1  ]: 1 of 4 START sql table model public.dim_customer ............................... [RUN]
[0m14:41:43.345639 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_airflow_public, now model.airflow.dim_customer)
[0m14:41:43.346205 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_customer
[0m14:41:43.378201 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_customer"
[0m14:41:43.379066 [debug] [Thread-1  ]: Began executing node model.airflow.dim_customer
[0m14:41:43.439682 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_customer"
[0m14:41:43.440661 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:41:43.441241 [debug] [Thread-1  ]: On model.airflow.dim_customer: BEGIN
[0m14:41:43.441788 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:41:43.445739 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:41:43.446364 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:41:43.446964 [debug] [Thread-1  ]: On model.airflow.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_customer"} */

  
    

  create  table "airflow"."public"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- dim_customer.sql

-- Create the dimension table
WITH customer_cte AS (
	SELECT DISTINCT
	    md5(cast(coalesce(cast(customerid as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(Country as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as customer_id,
	    Country AS country
	FROM products
	WHERE CustomerID IS NOT NULL
)
SELECT
    t.*,
	cm.iso
FROM customer_cte t
LEFT JOIN country cm ON t.country = cm.nicename
  );
  
[0m14:41:43.801565 [debug] [Thread-1  ]: SQL status: SELECT 4380 in 0.0 seconds
[0m14:41:43.811911 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:41:43.812624 [debug] [Thread-1  ]: On model.airflow.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_customer"} */
alter table "airflow"."public"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m14:41:43.813614 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:41:43.841312 [debug] [Thread-1  ]: On model.airflow.dim_customer: COMMIT
[0m14:41:43.842073 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:41:43.842694 [debug] [Thread-1  ]: On model.airflow.dim_customer: COMMIT
[0m14:41:43.847241 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m14:41:43.857737 [debug] [Thread-1  ]: Applying DROP to: "airflow"."public"."dim_customer__dbt_backup"
[0m14:41:43.864685 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_customer"
[0m14:41:43.865422 [debug] [Thread-1  ]: On model.airflow.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_customer"} */
drop table if exists "airflow"."public"."dim_customer__dbt_backup" cascade
[0m14:41:43.866422 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m14:41:43.870031 [debug] [Thread-1  ]: On model.airflow.dim_customer: Close
[0m14:41:43.872511 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc05e1f0>]}
[0m14:41:43.873598 [info ] [Thread-1  ]: 1 of 4 OK created sql table model public.dim_customer .......................... [[32mSELECT 4380[0m in 0.53s]
[0m14:41:43.874719 [debug] [Thread-1  ]: Finished running node model.airflow.dim_customer
[0m14:41:43.875443 [debug] [Thread-1  ]: Began running node model.airflow.dim_datetime
[0m14:41:43.876247 [info ] [Thread-1  ]: 2 of 4 START sql table model public.dim_datetime ............................... [RUN]
[0m14:41:43.877189 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.airflow.dim_customer, now model.airflow.dim_datetime)
[0m14:41:43.877822 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_datetime
[0m14:41:43.882928 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_datetime"
[0m14:41:43.883907 [debug] [Thread-1  ]: Began executing node model.airflow.dim_datetime
[0m14:41:43.893572 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_datetime"
[0m14:41:43.894875 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:41:43.895914 [debug] [Thread-1  ]: On model.airflow.dim_datetime: BEGIN
[0m14:41:43.896628 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:41:43.901119 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:41:43.901926 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:41:43.902694 [debug] [Thread-1  ]: On model.airflow.dim_datetime: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_datetime"} */

  
    

  create  table "airflow"."public"."dim_datetime__dbt_tmp"
  
  
    as
  
  (
    -- dim_datetime.sql

-- Create a CTE to extract date and time components
WITH datetime_cte AS (  
  SELECT DISTINCT
    invoicedate AS datetime_id,
    CASE
      WHEN LENGTH(CAST(invoicedate AS VARCHAR)) = 16 THEN
        -- Date format: "DD/MM/YYYY HH:MI"
        TO_TIMESTAMP(CAST(invoicedate as TEXT ), 'DD/MM/YYYY HH24:MI')
      WHEN LENGTH(CAST(invoicedate AS VARCHAR)) <= 14 THEN
        -- Date format: "MM/DD/YY HH:MI"

        TO_TIMESTAMP(CAST(invoicedate as TEXT ), 'MM/DD/YY HH24:MI')
      ELSE
        NULL
    END AS date_part
  FROM products
  WHERE invoicedate IS NOT NULL
)
SELECT
  datetime_id,
  date_part AS datetime,
  EXTRACT(YEAR FROM date_part) AS year,
  EXTRACT(MONTH FROM date_part) AS month,
  EXTRACT(DAY FROM date_part) AS day,
  EXTRACT(HOUR FROM date_part) AS hour,
  EXTRACT(MINUTE FROM date_part) AS minute,
  EXTRACT(ISODOW FROM date_part) AS weekday
FROM datetime_cte
  );
  
[0m14:41:44.300065 [debug] [Thread-1  ]: SQL status: SELECT 23260 in 0.0 seconds
[0m14:41:44.306818 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:41:44.307526 [debug] [Thread-1  ]: On model.airflow.dim_datetime: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_datetime"} */
alter table "airflow"."public"."dim_datetime__dbt_tmp" rename to "dim_datetime"
[0m14:41:44.308596 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:41:44.311328 [debug] [Thread-1  ]: On model.airflow.dim_datetime: COMMIT
[0m14:41:44.311962 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:41:44.312583 [debug] [Thread-1  ]: On model.airflow.dim_datetime: COMMIT
[0m14:41:44.317858 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m14:41:44.322853 [debug] [Thread-1  ]: Applying DROP to: "airflow"."public"."dim_datetime__dbt_backup"
[0m14:41:44.324391 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_datetime"
[0m14:41:44.325058 [debug] [Thread-1  ]: On model.airflow.dim_datetime: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_datetime"} */
drop table if exists "airflow"."public"."dim_datetime__dbt_backup" cascade
[0m14:41:44.326046 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m14:41:44.328417 [debug] [Thread-1  ]: On model.airflow.dim_datetime: Close
[0m14:41:44.329487 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc05e1f0>]}
[0m14:41:44.330560 [info ] [Thread-1  ]: 2 of 4 OK created sql table model public.dim_datetime .......................... [[32mSELECT 23260[0m in 0.45s]
[0m14:41:44.331710 [debug] [Thread-1  ]: Finished running node model.airflow.dim_datetime
[0m14:41:44.332545 [debug] [Thread-1  ]: Began running node model.airflow.dim_product
[0m14:41:44.333585 [info ] [Thread-1  ]: 3 of 4 START sql table model public.dim_product ................................ [RUN]
[0m14:41:44.334544 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.airflow.dim_datetime, now model.airflow.dim_product)
[0m14:41:44.335219 [debug] [Thread-1  ]: Began compiling node model.airflow.dim_product
[0m14:41:44.343400 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.dim_product"
[0m14:41:44.344573 [debug] [Thread-1  ]: Began executing node model.airflow.dim_product
[0m14:41:44.354621 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.dim_product"
[0m14:41:44.355731 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:41:44.356436 [debug] [Thread-1  ]: On model.airflow.dim_product: BEGIN
[0m14:41:44.357239 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:41:44.361966 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:41:44.362720 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:41:44.363389 [debug] [Thread-1  ]: On model.airflow.dim_product: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_product"} */

  
    

  create  table "airflow"."public"."dim_product__dbt_tmp"
  
  
    as
  
  (
    -- dim_product.sql
-- StockCode isn't unique, a product with the same id can have different and prices
-- Create the dimension table
SELECT DISTINCT
    md5(cast(coalesce(cast(stockcode as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(description as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(unitprice as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as product_id,
		stockcode AS stock_code,
    description AS description,
    unitprice AS price
FROM products
WHERE stockcode IS NOT NULL
AND unitprice > 0
  );
  
[0m14:41:46.179531 [debug] [Thread-1  ]: SQL status: SELECT 16282 in 2.0 seconds
[0m14:41:46.186082 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:41:46.186726 [debug] [Thread-1  ]: On model.airflow.dim_product: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_product"} */
alter table "airflow"."public"."dim_product__dbt_tmp" rename to "dim_product"
[0m14:41:46.187654 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:41:46.190235 [debug] [Thread-1  ]: On model.airflow.dim_product: COMMIT
[0m14:41:46.190840 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:41:46.191400 [debug] [Thread-1  ]: On model.airflow.dim_product: COMMIT
[0m14:41:46.196023 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m14:41:46.248351 [debug] [Thread-1  ]: Applying DROP to: "airflow"."public"."dim_product__dbt_backup"
[0m14:41:46.249800 [debug] [Thread-1  ]: Using postgres connection "model.airflow.dim_product"
[0m14:41:46.250402 [debug] [Thread-1  ]: On model.airflow.dim_product: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.dim_product"} */
drop table if exists "airflow"."public"."dim_product__dbt_backup" cascade
[0m14:41:46.251295 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m14:41:46.253278 [debug] [Thread-1  ]: On model.airflow.dim_product: Close
[0m14:41:46.254141 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fbd45ca0>]}
[0m14:41:46.255106 [info ] [Thread-1  ]: 3 of 4 OK created sql table model public.dim_product ........................... [[32mSELECT 16282[0m in 1.92s]
[0m14:41:46.256176 [debug] [Thread-1  ]: Finished running node model.airflow.dim_product
[0m14:41:46.257717 [debug] [Thread-1  ]: Began running node model.airflow.fct_invoices
[0m14:41:46.258569 [info ] [Thread-1  ]: 4 of 4 START sql table model public.fct_invoices ............................... [RUN]
[0m14:41:46.259375 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.airflow.dim_product, now model.airflow.fct_invoices)
[0m14:41:46.260023 [debug] [Thread-1  ]: Began compiling node model.airflow.fct_invoices
[0m14:41:46.271798 [debug] [Thread-1  ]: Writing injected SQL for node "model.airflow.fct_invoices"
[0m14:41:46.272829 [debug] [Thread-1  ]: Began executing node model.airflow.fct_invoices
[0m14:41:46.283403 [debug] [Thread-1  ]: Writing runtime sql for node "model.airflow.fct_invoices"
[0m14:41:46.284414 [debug] [Thread-1  ]: Using postgres connection "model.airflow.fct_invoices"
[0m14:41:46.285145 [debug] [Thread-1  ]: On model.airflow.fct_invoices: BEGIN
[0m14:41:46.285795 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m14:41:46.290421 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m14:41:46.291139 [debug] [Thread-1  ]: Using postgres connection "model.airflow.fct_invoices"
[0m14:41:46.291815 [debug] [Thread-1  ]: On model.airflow.fct_invoices: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.fct_invoices"} */

  
    

  create  table "airflow"."public"."fct_invoices__dbt_tmp"
  
  
    as
  
  (
    -- fct_invoices.sql

-- Create the fact table by joining the relevant keys from dimension table
WITH fct_invoices_cte AS (
    SELECT
        invoiceno AS invoice_id,
        invoicedate AS datetime_id,
        md5(cast(coalesce(cast(stockcode as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(description as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(unitprice as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as product_id,
        md5(cast(coalesce(cast(customerid as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as customer_id,
        quantity AS quantity,
        quantity * unitprice AS total
    FROM products
    WHERE quantity > 0
)
SELECT
    fi.invoice_id,
    dt.datetime_id,
    dp.product_id,
    dc.customer_id,
    fi.quantity,
    fi.total
FROM fct_invoices_cte fi
INNER JOIN "airflow"."public"."dim_datetime" dt ON fi.datetime_id = dt.datetime_id
INNER JOIN "airflow"."public"."dim_product" dp ON fi.product_id = dp.product_id
INNER JOIN "airflow"."public"."dim_customer" dc ON fi.customer_id = dc.customer_id
  );
  
[0m14:41:49.876093 [debug] [Thread-1  ]: SQL status: SELECT 397884 in 4.0 seconds
[0m14:41:49.882136 [debug] [Thread-1  ]: Using postgres connection "model.airflow.fct_invoices"
[0m14:41:49.882868 [debug] [Thread-1  ]: On model.airflow.fct_invoices: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.fct_invoices"} */
alter table "airflow"."public"."fct_invoices__dbt_tmp" rename to "fct_invoices"
[0m14:41:49.883920 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:41:49.887001 [debug] [Thread-1  ]: On model.airflow.fct_invoices: COMMIT
[0m14:41:49.887698 [debug] [Thread-1  ]: Using postgres connection "model.airflow.fct_invoices"
[0m14:41:49.888345 [debug] [Thread-1  ]: On model.airflow.fct_invoices: COMMIT
[0m14:41:49.919179 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m14:41:49.924019 [debug] [Thread-1  ]: Applying DROP to: "airflow"."public"."fct_invoices__dbt_backup"
[0m14:41:49.925594 [debug] [Thread-1  ]: Using postgres connection "model.airflow.fct_invoices"
[0m14:41:49.926247 [debug] [Thread-1  ]: On model.airflow.fct_invoices: /* {"app": "dbt", "dbt_version": "1.8.3", "profile_name": "airflow", "target_name": "dev", "node_id": "model.airflow.fct_invoices"} */
drop table if exists "airflow"."public"."fct_invoices__dbt_backup" cascade
[0m14:41:49.927210 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m14:41:49.929292 [debug] [Thread-1  ]: On model.airflow.fct_invoices: Close
[0m14:41:49.930248 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cc640fe-bd5e-44d6-a19f-9013e4784d54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc903d00>]}
[0m14:41:49.931261 [info ] [Thread-1  ]: 4 of 4 OK created sql table model public.fct_invoices .......................... [[32mSELECT 397884[0m in 3.67s]
[0m14:41:49.932398 [debug] [Thread-1  ]: Finished running node model.airflow.fct_invoices
[0m14:41:49.934252 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:49.935204 [debug] [MainThread]: On master: BEGIN
[0m14:41:49.936092 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:41:49.941353 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:41:49.942393 [debug] [MainThread]: On master: COMMIT
[0m14:41:49.943326 [debug] [MainThread]: Using postgres connection "master"
[0m14:41:49.944275 [debug] [MainThread]: On master: COMMIT
[0m14:41:49.945368 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:41:49.946366 [debug] [MainThread]: On master: Close
[0m14:41:49.947734 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:41:49.948730 [debug] [MainThread]: Connection 'model.airflow.fct_invoices' was properly closed.
[0m14:41:49.949878 [info ] [MainThread]: 
[0m14:41:49.950925 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 6.74 seconds (6.74s).
[0m14:41:49.954270 [debug] [MainThread]: Command end result
[0m14:41:50.044845 [info ] [MainThread]: 
[0m14:41:50.045706 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:41:50.046351 [info ] [MainThread]: 
[0m14:41:50.047039 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m14:41:50.048380 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.5060806, "process_user_time": 2.558001, "process_kernel_time": 0.096075, "process_mem_max_rss": "107684", "process_in_blocks": "232", "process_out_blocks": "2248"}
[0m14:41:50.049329 [debug] [MainThread]: Command `dbt run` succeeded at 14:41:50.049159 after 7.51 seconds
[0m14:41:50.050025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023ff822940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc9b7d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7023fc9b75b0>]}
[0m14:41:50.050708 [debug] [MainThread]: Flushing usage events
