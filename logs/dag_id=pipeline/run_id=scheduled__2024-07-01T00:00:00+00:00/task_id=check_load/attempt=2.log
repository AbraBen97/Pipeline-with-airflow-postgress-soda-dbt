[2024-07-02T12:39:32.493+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pipeline.check_load scheduled__2024-07-01T00:00:00+00:00 [queued]>
[2024-07-02T12:39:32.502+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pipeline.check_load scheduled__2024-07-01T00:00:00+00:00 [queued]>
[2024-07-02T12:39:32.502+0000] {taskinstance.py:2171} INFO - Starting attempt 2 of 2
[2024-07-02T12:39:32.518+0000] {taskinstance.py:2192} INFO - Executing <Task(_PythonExternalDecoratedOperator): check_load> on 2024-07-01 00:00:00+00:00
[2024-07-02T12:39:32.523+0000] {standard_task_runner.py:60} INFO - Started process 624 to run task
[2024-07-02T12:39:32.526+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'pipeline', 'check_load', 'scheduled__2024-07-01T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpdp0e8zdj']
[2024-07-02T12:39:32.527+0000] {standard_task_runner.py:88} INFO - Job 8: Subtask check_load
[2024-07-02T12:39:32.570+0000] {task_command.py:423} INFO - Running <TaskInstance: pipeline.check_load scheduled__2024-07-01T00:00:00+00:00 [running]> on host 11fbd99a881f
[2024-07-02T12:39:32.636+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='pipeline' AIRFLOW_CTX_TASK_ID='check_load' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T00:00:00+00:00'
[2024-07-02T12:39:32.668+0000] {python.py:903} WARNING - When checking for Airflow installed in virtual environment got Command '['/opt/airflow/soda_venv/bin/python', '-c', 'from airflow import __version__; print(__version__)']' returned non-zero exit status 1.
[2024-07-02T12:39:32.670+0000] {python.py:904} WARNING - This means that Airflow is not properly installed by  /opt/***/soda_venv/bin/python. Airflow context keys will not be available. Please Install Airflow 2.8.0 in your environment to access them.
[2024-07-02T12:39:32.866+0000] {process_utils.py:182} INFO - Executing cmd: /opt/***/soda_venv/bin/python /tmp/venv-callj8c8_n_1/script.py /tmp/venv-callj8c8_n_1/script.in /tmp/venv-callj8c8_n_1/script.out /tmp/venv-callj8c8_n_1/string_args.txt /tmp/venv-callj8c8_n_1/termination.log
[2024-07-02T12:39:32.875+0000] {process_utils.py:186} INFO - Output:
[2024-07-02T12:39:36.393+0000] {process_utils.py:190} INFO - Running Soda Scan ...
[2024-07-02T12:39:36.393+0000] {process_utils.py:190} INFO - INFO   | Soda Core 3.0.45
[2024-07-02T12:39:36.394+0000] {process_utils.py:190} INFO - DEBUG  | Reading configuration file "/opt/***/dossier/soda/configuration/configuration.yml"
[2024-07-02T12:39:36.394+0000] {process_utils.py:190} INFO - DEBUG  | Reading SodaCL file "/opt/***/dossier/soda/checks//premier_checks.yml"
[2024-07-02T12:39:36.395+0000] {process_utils.py:190} INFO - DEBUG  | Scan execution starts
[2024-07-02T12:39:36.395+0000] {process_utils.py:190} INFO - DEBUG  | Postgres connection properties: host="postgres", port="None", database="***", user="***", options="-c search_path=public", connection_timeout="None"
[2024-07-02T12:39:36.396+0000] {process_utils.py:190} INFO - DEBUG  | Query bdpostgres.products.schema[products]:
[2024-07-02T12:39:36.396+0000] {process_utils.py:190} INFO - SELECT column_name, data_type, is_nullable
[2024-07-02T12:39:36.397+0000] {process_utils.py:190} INFO - FROM information_schema.columns
[2024-07-02T12:39:36.397+0000] {process_utils.py:190} INFO - WHERE lower(table_name) = 'products'
[2024-07-02T12:39:36.397+0000] {process_utils.py:190} INFO -   AND lower(table_catalog) = '***'
[2024-07-02T12:39:36.398+0000] {process_utils.py:190} INFO -   AND lower(table_schema) = 'public'
[2024-07-02T12:39:36.398+0000] {process_utils.py:190} INFO - ORDER BY ORDINAL_POSITION
[2024-07-02T12:39:36.399+0000] {process_utils.py:190} INFO - INFO   | Scan summary:
[2024-07-02T12:39:36.399+0000] {process_utils.py:190} INFO - DEBUG  | 1/1 query OK
[2024-07-02T12:39:36.400+0000] {process_utils.py:190} INFO - DEBUG  |   bdpostgres.products.schema[products] [OK] 0:00:00.006131
[2024-07-02T12:39:36.401+0000] {process_utils.py:190} INFO - INFO   | 1/1 check PASSED:
[2024-07-02T12:39:36.401+0000] {process_utils.py:190} INFO - INFO   |     products in bdpostgres
[2024-07-02T12:39:36.402+0000] {process_utils.py:190} INFO - INFO   |       Schema Check [/opt/***/dossier/soda/checks//premier_checks.yml] [PASSED]
[2024-07-02T12:39:36.402+0000] {process_utils.py:190} INFO - INFO   |         schema_measured = [invoiceno text, stockcode text, description text, quantity integer, invoicedate timestamp without time zone, unitprice real, customerid real, country text]
[2024-07-02T12:39:36.403+0000] {process_utils.py:190} INFO - INFO   | All is good. No failures. No warnings. No errors.
[2024-07-02T12:39:36.403+0000] {process_utils.py:190} INFO - INFO   | Sending results to Soda Cloud
[2024-07-02T12:39:36.403+0000] {process_utils.py:190} INFO - INFO   | Soda Cloud Trace: 2734051978021689519
[2024-07-02T12:39:36.450+0000] {python.py:201} INFO - Done. Returned value was: None
[2024-07-02T12:39:36.462+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=pipeline, task_id=check_load, execution_date=20240701T000000, start_date=20240702T123932, end_date=20240702T123936
[2024-07-02T12:39:36.510+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-07-02T12:39:36.546+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
